import{_ as e,p as s,q as l,R as o,t as a}from"./framework-e03faf0e.js";const t={},c=o("p",null,"在目标检测任务中，经常会出现大量的负样本（背景）和较少的正样本（前景物体），导致类别不平衡。为了解决这个问题，Focal Loss 被设计成在训练过程中自动调整权重，使得学习更关注难以分类的样本，而降低对简单样本的关注。",-1),n=o("p",null,"Sigmoid 交叉熵损失用于二分类任务，计算公式如下： $$ \\begin{aligned} &L(p,y)=-[y*\\log(p)+(1-y)*\\log(1-p)] \\ & \\end{aligned} $$ 其中，$p$ 是模型预测的概率，$y$ 是真实标签（0 或 1）。",-1),_=o("p",null,"Sigmoid Focal Loss 通过引入一个调整因子来修改这个损失函数。这个调整因子的形式如下： $$ \\alpha(1-p)^\\gamma $$ 其中，$\\alpha$ 是一个介于 0 和 1 之间的权重系数，$\\gamma$ 是一个称为“聚焦参数”的非负实数。",-1),i=o("p",null,[a("将调整因子添加到 Sigmoid 交叉熵损失函数中，我们得到 Sigmoid Focal Loss： $$ FL(p,y)=-a*[y*(1-p)^{\\gamma}*\\log(p)+(1-y)"),o("em",null,"p^{\\gamma}"),a("\\log(1-p)] $$ 通过引入这个调整因子，Sigmoid Focal Loss 的值会随着预测概率接近正确标签而减小。这意味着模型在训练过程中对已经很容易正确分类的样本（高置信度预测）的关注度会降低，而对难以分类的样本（低置信度预测）的关注度会提高。这种动态调整有助于解决类别不平衡问题，从而提高目标检测任务的性能。")],-1),p=[c,n,_,i];function m($,d){return s(),l("div",null,p)}const r=e(t,[["render",m],["__file","Focal_Loss.html.vue"]]);export{r as default};
