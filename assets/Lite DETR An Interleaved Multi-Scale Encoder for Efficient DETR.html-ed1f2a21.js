import{_ as e,p as t,q as a,a1 as i}from"./framework-e03faf0e.js";const n={},p=i('<blockquote><p>Li, Feng, et al. &quot;Lite DETR: An Interleaved Multi-Scale Encoder for Efficient DETR.&quot; <em>arXiv preprint arXiv:2303.07335</em> (2023).</p></blockquote><h1 id="motivation" tabindex="-1"><a class="header-anchor" href="#motivation" aria-hidden="true">#</a> Motivation</h1><p>对于传统的DETR来说，随着使用到的特征图增多，计算成本会随特征token的数量呈二次方增长，因此DETR选择放弃使用低层次的特征图。然后低层次特征图对于检测小目标却至关重要，具有许多小目标的局部信息</p><p>为了解决这个问题，Deformable DETR开发了一种可变形注意力算法，通过将每个查询令牌与固定数量的采样点进行比较，将自注意力复杂度从二次降低到线性。基于这种高效的自注意计算，可变形DETR将多尺度特征引入到DETR中，可变形编码器已被广泛应用于后续类似DETR的模型</p><p>然而，由于多尺度特征引入了大量的查询令牌，可变形编码器仍然存在较高的计算成本</p><h1 id="模型" tabindex="-1"><a class="header-anchor" href="#模型" aria-hidden="true">#</a> 模型</h1><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/04/image-20230504142928313.png" alt="image-20230504142928313"></p><p>与很多论文改进解码器的方向不同，本文模型主要更改了DETR类模型的编码器部分，这也使得该模型可以插入到目前大多先进的DETR类模型</p><h2 id="交错更新" tabindex="-1"><a class="header-anchor" href="#交错更新" aria-hidden="true">#</a> 交错更新</h2><p>论文将特征S分为低级特征$F_L$和高级特征$F_H$，$N_H$和$N_L$是相应的token数量。$F_H$可以在不同的设置中包含前三个或两个尺度，为了清晰起见，将$F_H$设置为S1、S2、S3，$F_L$默认为S4。$F_H$被视为主要特征，更新频率较高，而$F_L$因为包含大量的冗余信息，因此更新频率较低。由于可变形注意力与特征查询具有线性复杂性，因此频繁更新少量的高级特征在很大程度上降低了计算成本。将高效编码器块堆叠B次，其中每个块更新高级特征A次，但仅在块结束时更新低级特征一次。通过这种方式，可以以低得多的计算成本来维持全尺寸的特征金字塔</p><ol><li><p>对于$F_H$ $$ \\begin{aligned} \\textbf{Q}&amp; =F_H,\\textbf{K}=\\textbf{V}=Concat(F_H,F_L) \\ F&#39;_H&amp; =KDA(\\textbf{Q},\\textbf{K},\\textbf{V}) \\ \\textit{Output}&amp; =Concat(F_H&#39;,F_L) \\end{aligned} $$</p></li><li><p>对于$F_L$ $$ \\begin{aligned} \\textbf{Q}&amp; =F_L,\\textbf{K}=\\textbf{V}=Concat(F_H&#39;,F_L) \\ F&#39;_L&amp; =KDA(\\textbf{Q},\\textbf{K},\\textbf{V}) \\ \\textit{Output}&amp; =Concat(F_L&#39;,F_H&#39;) \\end{aligned} $$</p></li></ol><h2 id="kda注意力" tabindex="-1"><a class="header-anchor" href="#kda注意力" aria-hidden="true">#</a> KDA注意力</h2><p>可变形注意力层没有用到key，直接使用全连接层来计算权重，这表明查询可以仅通过其特征来决定每个采样值的重要性，而无需将其与key进行比较。由于所有的多尺度特征都是对采样位置和注意力权重的查询，因此原始模型可以快速学习如何在给定查询的情况下评估每个采样位置的重要性。然而，论文编码器中的交错更新使查询难以决定其他异步特征图中的注意力权重和采样位置 $$ \\begin{aligned} \\textbf{V}=Samp(S,p+\\Delta p)W^V, \\ \\textbf{K}=Samp(S,p+\\Delta p)W^K, \\ KDA(\\textbf{Q},\\textbf{K},\\textbf{V}) =Softmax(\\dfrac{\\textbf{QK}^T}{\\sqrt{d_k}})\\textbf{V} \\end{aligned} $$ <img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/04/image-20230504150656145.png" alt="image-20230504150656145" style="zoom:50%;"></p><h1 id="实验" tabindex="-1"><a class="header-anchor" href="#实验" aria-hidden="true">#</a> 实验</h1><p>与其他高效变体相比，论文的高效设计不受特定检测框架的限制，并且可以很容易地插入到其他基于DETR的模型中。论文以DINO和H-DETR为例来展示高效编码器的有效性。本文的模型在计算成本相当的情况下实现了显著更好的性能。此外，插入高效的编码器后，编码器的GFLOPs与原始编码器相比可以减少78%~62%，同时保持99%的原始性能。具体而言，基于Swin Tiny，Lite DINO仅用159 GFLOPs实现了53.9 AP，在相同的GFLOP下也优于YOLO系列</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/04/image-20230504151635628.png" alt="image-20230504151635628"></p><p>作者还做了消融实现，发现论文设计到的高级融合、低级融合和KDA注意力这些小组件的加入，都不会显著提升模型的GFLOPs，但是却可以快速提升模型AP</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/04/image-20230504151729762.png" alt="image-20230504151729762"></p><p>论文还讨论了超参数（编码器块数量、高级融合次数、高级特征比例）的设置，发现编码器块数量提升会提高模型表现，但大于3后，不会再提升模型的性能；当使用更多的高级特征尺度，来更新低级特征时，性能会提高。</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/04/image-20230504203308379.png" alt="image-20230504203308379"></p>',20),r=[p];function c(o,d){return t(),a("div",null,r)}const s=e(n,[["render",c],["__file","Lite DETR An Interleaved Multi-Scale Encoder for Efficient DETR.html.vue"]]);export{s as default};
