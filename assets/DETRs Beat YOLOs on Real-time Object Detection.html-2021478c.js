import{_ as i,M as n,p as r,q as c,R as t,t as e,N as s,a1 as a}from"./framework-e03faf0e.js";const p={},l=a('<blockquote><p>Lv, Wenyu, et al. &quot;Detrs beat yolos on real-time object detection.&quot; <em>arXiv preprint arXiv:2304.08069</em> (2023).</p></blockquote><h1 id="motivation" tabindex="-1"><a class="header-anchor" href="#motivation" aria-hidden="true">#</a> Motivation</h1><ul><li>经过这些年的发展，YOLO已经成为了实时目标检测器的代名词，研究发现，anchor已经不再是限制YOLO发展的主要因素，而是大量冗余的边界框，它们需要使用后处理NMS步骤来进行过滤，这导致了性能的瓶颈，并且它的超参数设置也会严重的影响模型的精度和速度，作者认为这并不符合实时目标检测器的理念</li><li>最近DETR类的检测器训练收敛速度加快、优化简单，取得了非常好的表现。然而高计算量的问题依旧没有得到很好的解决，使得DETR难以发挥它的优势来应用到实时检测领域</li><li>从前面的工作中可以发现，object query的初始化策略对于模型表现是非常重要的</li></ul><p>本文提出了一个Real-Time DEtection TRansformer (RT-DETR)，第一个实时的端到端目标检测器，RT-DETR不仅在准确率和速度上都超越了现有的实时检测器，同时还不需要后处理等操作，使得推理速度不会延迟并且保持稳定。</p><h1 id="模型" tabindex="-1"><a class="header-anchor" href="#模型" aria-hidden="true">#</a> 模型</h1><p>论文先是对NMS进行了分析，发现score阈值和IoU阈值的设置，极大的影响了模型的准确性和速度。score阈值会显著减少生成的预测框数量。</p><p>对大量端到端的实时检测器进行了速度测试，得出：对于需要NMS后处理的模型，在相同精度下anchor-free模型表现要超越anchor-base模型，这是因为前者生成的预测框要远少于后者（少三倍多）</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/05/image-20230505091635460.png" alt="image-20230505091635460"></p><h2 id="高效混合编码器" tabindex="-1"><a class="header-anchor" href="#高效混合编码器" aria-hidden="true">#</a> 高效混合编码器</h2><p>作者认为同一尺度内和尺度间的同时交互是低效的。与论文[Lite DETR](Lite DETR An Interleaved Multi-Scale Encoder for Efficient DETR.md)一样，高级特征和低级特征的频繁交互是冗余的。</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/05/image-20230505095218587.png" alt="image-20230505095218587"></p><p>模型包含两个模块：基于注意力的尺度内融合AIFI模块和基于CNN的跨尺度特征融合模块CCFM</p><p><strong>==AIFI==</strong>：</p><p>🌟 该模块只作用在S5特征图上，因为作者认为将自注意操作应用于具有更丰富语义概念的高级特征可以捕获图像中概念实体之间的联系。而低级特征由于缺乏语义概念，并且存在与高级特征交互重复和混淆的风险，因此低级特征的<strong>尺度内</strong>交互是不必要的。论文实验也证明了这点，不仅可以加快计算速度，而且准确率还能提升0.4个点。</p><p><strong>==CCFM==</strong>：</p><p>类似于双向融合，在fusion模块中堆叠了N个RepBlock块</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/05/image-20230505100556982.png" alt="image-20230505100556982"></p><h2 id="iou感知query" tabindex="-1"><a class="header-anchor" href="#iou感知query" aria-hidden="true">#</a> IoU感知Query</h2><p>之前的方法使用分类得分top k的k个特征的初始化object query（或者只是初始化position query），然而由于分类得分和位置置信度分布不一致，一些预测框分类得分高，但不接近GT框，导致分类得分高，IoU得分低的框被选中，而分类得分低，IoU得分高的框被丢弃。</p><p>因此本文提出了IoU感知Query，约束模型为IoU高的框生成高的分类得分，IoU低的框生成低的分类得分，这样在选择top-k个特征时，query都会同时具备较高的IoU得分和分类得分</p>',20),h={href:"https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VarifocalNet_An_IoU-Aware_Dense_Object_Detector_CVPR_2021_paper.html",target:"_blank",rel:"noopener noreferrer"},m=t("em",null,"{box}(\\hat{b},b)+\\mathcal{L}",-1),u=t("em",null,"{box}(\\hat{b},b)+\\mathcal{L}",-1),d=a('<h2 id="模型规模" tabindex="-1"><a class="header-anchor" href="#模型规模" aria-hidden="true">#</a> 模型规模</h2><p>作者还探讨了不同规模的模型在性能和FPS上的表现。将原来的ResNet backbone换成HGNetv2，更改fusion block中的RepBlock的数量和embedding的维度来对模型规模进行调整。对于 Decoder ，并没有对其结构进行调整，目的是为了方便使用高精度的 DETR 的大检测模型对轻量级 DETR 检测器进行蒸馏，作者认为这是未来可探索的一个方向。</p><h1 id="实验" tabindex="-1"><a class="header-anchor" href="#实验" aria-hidden="true">#</a> 实验</h1><ul><li><p>在精度和速度上都超越了yolo检测器。也超越了相同backbone的端到端检测器</p></li><li><p>通过一系列消融实验，讨论分析了几种多尺度特征融合方式，说明尺度内、尺度间的特征交互是非常重要的；分离尺度内交互和跨尺度融合可以在提高精度的同时降低计算量；低层特征的尺度内交互是不必要的</p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/05/image-20230505095037600.png" alt="image-20230505095037600" style="zoom:50%;"></li><li><p>实验结果表明，IoU 感知查询选择方法选取的编码器特征不仅提高了高分类分数的比例（0.82% 对比 0.35%），而且提供了更多具有高分类分数和高 IoU 分数的特征（0.67% 对比 0.30%）</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/06/image-20230506194016290.png" alt="image-20230506194016290"></p></li><li><p>当解码器层数为 6 时，检测器实现了最佳准确性，达到 53.1% 的 AP；作者还发现随着解码器层索引的增加，相邻解码器层之间的准确性差异逐渐减小，以 6 层解码器为例，使用 5 层进行推理时，准确性只损失了 0.1% 的 AP（53.1% AP 对比 53.0% AP），同时将延迟减少了 0.5 毫秒（9.3 毫秒对比 8.8 毫秒）因此，RT-DETR 支持通过使用不同的解码器层数灵活调整推理速度，无需重新训练即可进行推理。这有助于实时检测器在实际应用中的普及</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/06/image-20230506194414112.png" alt="image-20230506194414112"></p></li></ul>',4);function g(_,b){const o=n("ExternalLinkIcon");return r(),c("div",null,[l,t("p",null,[e("作者选择更改目标检测器的损失函数，与"),t("a",h,[e("VFL"),s(o)]),e("模型一样，通过在训练期间约束检测器对高 IoU 的特征产生高分类分数，对低 IoU 的特征产生低分类分数。从而使得模型根据分类分数选择的 top-K 特征对应的预测框同时具有高分类分数和高 IoU 分数。 $$ \\begin{aligned} \\mathcal{L}(\\hat{y},y)& =\\mathcal{L}"),m,e("{cls}(\\hat{c},\\hat{b},y,\\text{b}) \\ &=\\mathcal{L}"),u,e("{cls}(\\hat{c},c,{IoU}) \\end{aligned} $$")]),d])}const f=i(p,[["render",g],["__file","DETRs Beat YOLOs on Real-time Object Detection.html.vue"]]);export{f as default};
