import{_ as o,p as t,q as N,a1 as r}from"./framework-e03faf0e.js";const s={},n=r("<p>Faster RCNN训练过程可以分为四个步骤：</p><ol><li><p><strong>预训练 RPN</strong>：首先，独立训练 RPN。使用基础 CNN（如 VGG、ResNet 等）从输入图像中提取特征图。然后，在特征图上使用滑动窗口方法生成锚点（anchor）框。对每个锚点框，计算与真实边界框（ground truth bounding box）的 IoU（交并比），并为锚点框分配正负样本标签。接下来，根据正负样本标签训练一个二分类器（用于区分前景和背景）以及一个边界框回归器（用于优化锚点框的位置和大小）。这个阶段通常采用随机梯度下降（SGD）方法进行优化。</p><blockquote><p>预训练 RPN（Region Proposal Network）时，我们需要计算两部分的损失：一部分是分类损失，即预测一个候选框是否包含物体；另一部分是回归损失，即预测边界框的精确位置。为了计算这两部分损失，我们需要为每个 anchor 分配正样本（物体）和负样本（背景）标签。</p><p>在 RPN 中，正负样本的分配规则如下：</p><ol><li>对于与真实边界框具有最大 IoU 的 anchor，将其分配为正样本。</li><li>对于与任何真实边界框的 IoU 大于预定义阈值（如 0.7）的 anchor，将其分配为正样本。</li><li>对于与所有真实边界框的 IoU 都小于另一个预定义阈值（如 0.3）的 anchor，将其分配为负样本。</li><li>对于 IoU 处于 0.3-0.7 之间的 anchor，通常被视为不确定的样本，这些样本在 RPN 训练阶段被忽略。</li></ol><p>正负样本损失计算如下：</p><ol><li><strong>分类损失</strong>：采用二元交叉熵损失（binary cross-entropy loss）计算正负样本的分类损失。对于每个 anchor，我们预测一个概率值，表示该 anchor 包含物体的概率。然后，我们将预测概率与真实标签（1 表示正样本，0 表示负样本）进行比较，计算二元交叉熵损失。</li><li><strong>回归损失</strong>：对于正样本，我们需要预测边界框的位置。通常采用 Smooth L1 损失计算回归损失。首先，我们计算 anchor 与真实边界框之间的偏移量（例如，中心点坐标和宽高的差值）。然后，我们预测这些偏移量，并与真实偏移量进行比较，计算 Smooth L1 损失。注意，只有正样本需要计算回归损失，负样本不需要。</li></ol><p>在训练 RPN 时，我们将分类损失和回归损失相加，得到总损失。通过最小化总损失，我们可以优化 RPN 的性能，提高物体候选框的质量。</p></blockquote></li><li><p><strong>预训练 Fast R-CNN 分类器</strong>：在这个阶段，我们先独立训练 Fast R-CNN 分类器。利用在 RPN 训练过程中产生的 RoI 提议，结合输入图像的真实边界框标签，训练一个多分类器（用于识别不同类别的物体）以及一个边界框回归器（用于进一步优化物体边界框的位置和大小）。与 RPN 训练阶段类似，这里也采用 SGD 方法进行优化。</p></li><li><p><strong>联合训练 RPN 和 Fast R-CNN 分类器</strong>：在完成了两个独立训练阶段后，我们将 RPN 和 Fast R-CNN 分类器整合到一个完整的 Faster R-CNN 模型中，进行联合训练。在这个阶段，我们固定基础 CNN 的权重，分别更新 RPN 和 Fast R-CNN 分类器的权重。联合训练的目的是为了使 RPN 和 Fast R-CNN 分类器能够更好地协同工作，提高目标检测的性能。</p></li><li><p><strong>微调</strong>：为了进一步优化 Faster R-CNN 的性能，我们可以对整个网络（包括基础 CNN、RPN 和 Fast R-CNN 分类器）进行微调。在这个阶段，我们需要使用较小的学习率，避免在之前训练阶段获得的优良权重被破坏。</p></li></ol>",2),l=[n];function a(e,i){return t(),N("div",null,l)}const c=o(s,[["render",a],["__file","Faster_RCNN.html.vue"]]);export{c as default};
