<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.61">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>目录 | 记录</title><meta name="description" content="个人博客">
    <link rel="preload" href="/notebook/assets/style-72c644a3.css" as="style"><link rel="stylesheet" href="/notebook/assets/style-72c644a3.css">
    <link rel="modulepreload" href="/notebook/assets/app-29aba0ee.js"><link rel="modulepreload" href="/notebook/assets/framework-e03faf0e.js"><link rel="modulepreload" href="/notebook/assets/Dynamic Multiscale Graph Neural Networks for 3D Skeleton-Based Human Motion Prediction.html-65f68e7a.js"><link rel="modulepreload" href="/notebook/assets/Dynamic Multiscale Graph Neural Networks for 3D Skeleton-Based Human Motion Prediction.html-6eabf3f7.js"><link rel="prefetch" href="/notebook/assets/index.html-2ace7bb6.js" as="script"><link rel="prefetch" href="/notebook/assets/python.html-f7046045.js" as="script"><link rel="prefetch" href="/notebook/assets/blog.html-cfba2365.js" as="script"><link rel="prefetch" href="/notebook/assets/git.html-20eabbb7.js" as="script"><link rel="prefetch" href="/notebook/assets/jetbrains.html-1049a7bd.js" as="script"><link rel="prefetch" href="/notebook/assets/obsidian配置.html-c2b33983.js" as="script"><link rel="prefetch" href="/notebook/assets/three.html-c47c34ac.js" as="script"><link rel="prefetch" href="/notebook/assets/virtualenv.html-f88fa800.js" as="script"><link rel="prefetch" href="/notebook/assets/2023.04.27目标检测概述.html-f3c2e35c.js" as="script"><link rel="prefetch" href="/notebook/assets/2023.05.04FPN.html-1bdbd047.js" as="script"><link rel="prefetch" href="/notebook/assets/2023.05.11动作预测.html-0622b710.js" as="script"><link rel="prefetch" href="/notebook/assets/数据结构.html-9e5934b3.js" as="script"><link rel="prefetch" href="/notebook/assets/Docker.html-af4b735b.js" as="script"><link rel="prefetch" href="/notebook/assets/Maven.html-9468c922.js" as="script"><link rel="prefetch" href="/notebook/assets/Nginx.html-d7cc1b84.js" as="script"><link rel="prefetch" href="/notebook/assets/bash.html-137e9ab2.js" as="script"><link rel="prefetch" href="/notebook/assets/shell.html-1e644b7f.js" as="script"><link rel="prefetch" href="/notebook/assets/vim.html-8ee138e1.js" as="script"><link rel="prefetch" href="/notebook/assets/快速入门.html-afc25d48.js" as="script"><link rel="prefetch" href="/notebook/assets/原理解析.html-0e682a48.js" as="script"><link rel="prefetch" href="/notebook/assets/小知识点.html-375042f2.js" as="script"><link rel="prefetch" href="/notebook/assets/注解开发.html-ef417a35.js" as="script"><link rel="prefetch" href="/notebook/assets/AOP.html-8d768895.js" as="script"><link rel="prefetch" href="/notebook/assets/一个spring程序.html-7684c74d.js" as="script"><link rel="prefetch" href="/notebook/assets/声明式事务.html-46f2b627.js" as="script"><link rel="prefetch" href="/notebook/assets/整合Mybatis.html-24016c8e.js" as="script"><link rel="prefetch" href="/notebook/assets/Eureka.html-8d1b43f3.js" as="script"><link rel="prefetch" href="/notebook/assets/Feign.html-4e8e78f5.js" as="script"><link rel="prefetch" href="/notebook/assets/Hystrix.html-4bd24289.js" as="script"><link rel="prefetch" href="/notebook/assets/Ribbon.html-53740665.js" as="script"><link rel="prefetch" href="/notebook/assets/Zuul.html-2498ee57.js" as="script"><link rel="prefetch" href="/notebook/assets/初识SpringCloud.html-3b80e5d5.js" as="script"><link rel="prefetch" href="/notebook/assets/Jdbc.html-a7e8f990.js" as="script"><link rel="prefetch" href="/notebook/assets/Shiro.html-e44467e8.js" as="script"><link rel="prefetch" href="/notebook/assets/Swagger.html-911f6af4.js" as="script"><link rel="prefetch" href="/notebook/assets/Web静态资源处理.html-1f68088e.js" as="script"><link rel="prefetch" href="/notebook/assets/thymeleaf.html-ac0435f9.js" as="script"><link rel="prefetch" href="/notebook/assets/分布式.html-e19b2a12.js" as="script"><link rel="prefetch" href="/notebook/assets/异步、定时、邮件任务.html-7faaa219.js" as="script"><link rel="prefetch" href="/notebook/assets/整合mybatis.html-7afca196.js" as="script"><link rel="prefetch" href="/notebook/assets/第一天.html-98b6564d.js" as="script"><link rel="prefetch" href="/notebook/assets/第二天.html-573e1be5.js" as="script"><link rel="prefetch" href="/notebook/assets/ES6补充.html-b4cd5561.js" as="script"><link rel="prefetch" href="/notebook/assets/Vue基础.html-515cde43.js" as="script"><link rel="prefetch" href="/notebook/assets/Vue项目部署.html-f336f953.js" as="script"><link rel="prefetch" href="/notebook/assets/threejs的使用.html-ee030932.js" as="script"><link rel="prefetch" href="/notebook/assets/单文件组件.html-ff377a86.js" as="script"><link rel="prefetch" href="/notebook/assets/脚手架.html-e0f489e2.js" as="script"><link rel="prefetch" href="/notebook/assets/页面title.html-172b29b7.js" as="script"><link rel="prefetch" href="/notebook/assets/Bitmaps.html-79c742a3.js" as="script"><link rel="prefetch" href="/notebook/assets/Hyperloglog.html-d03cd507.js" as="script"><link rel="prefetch" href="/notebook/assets/Redis的基本事务操作.html-53b5c206.js" as="script"><link rel="prefetch" href="/notebook/assets/redis-benchmark性能测试.html-04679c0f.js" as="script"><link rel="prefetch" href="/notebook/assets/基本知识点.html-45da19a4.js" as="script"><link rel="prefetch" href="/notebook/assets/安装.html-57f6a802.js" as="script"><link rel="prefetch" href="/notebook/assets/集成Redis.html-d8f8d67c.js" as="script"><link rel="prefetch" href="/notebook/assets/Center_pooling.html-85cfbb9a.js" as="script"><link rel="prefetch" href="/notebook/assets/Focal_Loss.html-193c6d7b.js" as="script"><link rel="prefetch" href="/notebook/assets/MAE.html-4931b3e8.js" as="script"><link rel="prefetch" href="/notebook/assets/NMS非极大值抑制.html-09b3f293.js" as="script"><link rel="prefetch" href="/notebook/assets/corner_pooling.html-1e393616.js" as="script"><link rel="prefetch" href="/notebook/assets/smooth_L1_loss.html-91533a5e.js" as="script"><link rel="prefetch" href="/notebook/assets/CMU motion capture.html-6d30a9bd.js" as="script"><link rel="prefetch" href="/notebook/assets/Human3.6M.html-f42ef51e.js" as="script"><link rel="prefetch" href="/notebook/assets/Adapters.html-dd2b3a22.js" as="script"><link rel="prefetch" href="/notebook/assets/CLIP.html-c1dfee82.js" as="script"><link rel="prefetch" href="/notebook/assets/Faster_RCNN.html-a55276c4.js" as="script"><link rel="prefetch" href="/notebook/assets/MoCo.html-bdef694d.js" as="script"><link rel="prefetch" href="/notebook/assets/RoI池化层.html-af6a69eb.js" as="script"><link rel="prefetch" href="/notebook/assets/TCN.html-fe2792d8.js" as="script"><link rel="prefetch" href="/notebook/assets/VAE.html-d465ab46.js" as="script"><link rel="prefetch" href="/notebook/assets/soft-argmax.html-e9d8f707.js" as="script"><link rel="prefetch" href="/notebook/assets/元学习.html-3bfa8b9a.js" as="script"><link rel="prefetch" href="/notebook/assets/反投影（back-projecting）.html-6f4e64f6.js" as="script"><link rel="prefetch" href="/notebook/assets/对比学习.html-5acba346.js" as="script"><link rel="prefetch" href="/notebook/assets/训练技巧.html-6010d278.js" as="script"><link rel="prefetch" href="/notebook/assets/选择性搜索.html-c12ad804.js" as="script"><link rel="prefetch" href="/notebook/assets/A convnet for the 2020s.html-2bc17d6d.js" as="script"><link rel="prefetch" href="/notebook/assets/Co-occurrence Feature Learning from Skeleton Data.html-0b119cdf.js" as="script"><link rel="prefetch" href="/notebook/assets/DETRs Beat YOLOs on Real-time Object Detection.html-059b7cc2.js" as="script"><link rel="prefetch" href="/notebook/assets/Disentangling Identity and Pose for Facial Expression Recognition.html-f06badbb.js" as="script"><link rel="prefetch" href="/notebook/assets/EVOLVING REINFORCEMENT LEARNING ALGORITHMS.html-f3644afb.js" as="script"><link rel="prefetch" href="/notebook/assets/Lite DETR An Interleaved Multi-Scale Encoder for Efficient DETR.html-b8a67599.js" as="script"><link rel="prefetch" href="/notebook/assets/Long-term Human Motion Prediction with Scene Context.html-ba27a589.js" as="script"><link rel="prefetch" href="/notebook/assets/Real-time 2D Multi-Person Pose Estimation on CPU.html-5f3f363f.js" as="script"><link rel="prefetch" href="/notebook/assets/SSHFD Single Shot Human Fall Detection with Occlud.html-07421328.js" as="script"><link rel="prefetch" href="/notebook/assets/Scaling Up Your Kernels to 31x31 Revisiting Large.html-142b670f.js" as="script"><link rel="prefetch" href="/notebook/assets/SkeleMotion A New Representation of Skeleton Joint.html-da6c1581.js" as="script"><link rel="prefetch" href="/notebook/assets/Spatial Temporal Graph Convolutional Networks for.html-15a296fe.js" as="script"><link rel="prefetch" href="/notebook/assets/TSM Temporal Shift Module for Efficient Video Unde.html-ca0c4928.js" as="script"><link rel="prefetch" href="/notebook/assets/Towards Automated and Marker-less Parkinson Diseas.html-6428677a.js" as="script"><link rel="prefetch" href="/notebook/assets/Two-Stream Convolutional Networks for Action Recog.html-f82572e0.js" as="script"><link rel="prefetch" href="/notebook/assets/🌟LoGoNet_ Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion.html-f6c8bb99.js" as="script"><link rel="prefetch" href="/notebook/assets/概述.html-a7e5df19.js" as="script"><link rel="prefetch" href="/notebook/assets/时间序列模型.html-9fc0dadf.js" as="script"><link rel="prefetch" href="/notebook/assets/线性代数.html-61a67473.js" as="script"><link rel="prefetch" href="/notebook/assets/存储器.html-2f2b73aa.js" as="script"><link rel="prefetch" href="/notebook/assets/系统总线.html-2d2d0cb1.js" as="script"><link rel="prefetch" href="/notebook/assets/计算机基本组成.html-1a73a14e.js" as="script"><link rel="prefetch" href="/notebook/assets/计算机的运算方法.html-b45a09c0.js" as="script"><link rel="prefetch" href="/notebook/assets/输入输出系统.html-f55069c6.js" as="script"><link rel="prefetch" href="/notebook/assets/高速缓存存储器.html-4125fa28.js" as="script"><link rel="prefetch" href="/notebook/assets/JDBC.html-1144b752.js" as="script"><link rel="prefetch" href="/notebook/assets/JSP.html-c6cac9bd.js" as="script"><link rel="prefetch" href="/notebook/assets/Servlet.html-9ba02088.js" as="script"><link rel="prefetch" href="/notebook/assets/Tomcat.html-06755505.js" as="script"><link rel="prefetch" href="/notebook/assets/监听器.html-de7634dd.js" as="script"><link rel="prefetch" href="/notebook/assets/缓存.html-7b0cf2e7.js" as="script"><link rel="prefetch" href="/notebook/assets/过滤器.html-e0793ac7.js" as="script"><link rel="prefetch" href="/notebook/assets/IO.html-2e0c5c17.js" as="script"><link rel="prefetch" href="/notebook/assets/反射.html-f7cdd524.js" as="script"><link rel="prefetch" href="/notebook/assets/容器.html-db6f490e.js" as="script"><link rel="prefetch" href="/notebook/assets/泛型.html-b1b6fc4a.js" as="script"><link rel="prefetch" href="/notebook/assets/注解.html-77360df3.js" as="script"><link rel="prefetch" href="/notebook/assets/概述.html-31096f5b.js" as="script"><link rel="prefetch" href="/notebook/assets/CRUD.html-94f6d3a4.js" as="script"><link rel="prefetch" href="/notebook/assets/ResultMap结果集映射.html-9375f298.js" as="script"><link rel="prefetch" href="/notebook/assets/lombok.html-00261dd2.js" as="script"><link rel="prefetch" href="/notebook/assets/一对多.html-86fe7b2a.js" as="script"><link rel="prefetch" href="/notebook/assets/分页.html-a20de2b4.js" as="script"><link rel="prefetch" href="/notebook/assets/动态SQL.html-d031d0b3.js" as="script"><link rel="prefetch" href="/notebook/assets/日志.html-5ed4396e.js" as="script"><link rel="prefetch" href="/notebook/assets/概念.html-34c34093.js" as="script"><link rel="prefetch" href="/notebook/assets/注解开发.html-ae7c8458.js" as="script"><link rel="prefetch" href="/notebook/assets/生命周期和作用域.html-86ba199e.js" as="script"><link rel="prefetch" href="/notebook/assets/第一个Mybatis程序.html-119f379c.js" as="script"><link rel="prefetch" href="/notebook/assets/缓存.html-62196616.js" as="script"><link rel="prefetch" href="/notebook/assets/配置解析.html-977e55e4.js" as="script"><link rel="prefetch" href="/notebook/assets/404.html-f9875e7b.js" as="script"><link rel="prefetch" href="/notebook/assets/index.html-ffe77b09.js" as="script"><link rel="prefetch" href="/notebook/assets/python.html-d21cf8d7.js" as="script"><link rel="prefetch" href="/notebook/assets/blog.html-08f51f62.js" as="script"><link rel="prefetch" href="/notebook/assets/git.html-efb6cc88.js" as="script"><link rel="prefetch" href="/notebook/assets/jetbrains.html-35e31cc3.js" as="script"><link rel="prefetch" href="/notebook/assets/obsidian配置.html-b8178469.js" as="script"><link rel="prefetch" href="/notebook/assets/three.html-21938d7b.js" as="script"><link rel="prefetch" href="/notebook/assets/virtualenv.html-5d77a6db.js" as="script"><link rel="prefetch" href="/notebook/assets/2023.04.27目标检测概述.html-16497519.js" as="script"><link rel="prefetch" href="/notebook/assets/2023.05.04FPN.html-f21d36d1.js" as="script"><link rel="prefetch" href="/notebook/assets/2023.05.11动作预测.html-806a0f9e.js" as="script"><link rel="prefetch" href="/notebook/assets/数据结构.html-92d7751b.js" as="script"><link rel="prefetch" href="/notebook/assets/Docker.html-3a6d2ed2.js" as="script"><link rel="prefetch" href="/notebook/assets/Maven.html-67a72842.js" as="script"><link rel="prefetch" href="/notebook/assets/Nginx.html-9d4a40d0.js" as="script"><link rel="prefetch" href="/notebook/assets/bash.html-b0cab74f.js" as="script"><link rel="prefetch" href="/notebook/assets/shell.html-8399ebb8.js" as="script"><link rel="prefetch" href="/notebook/assets/vim.html-075c198f.js" as="script"><link rel="prefetch" href="/notebook/assets/快速入门.html-b652b302.js" as="script"><link rel="prefetch" href="/notebook/assets/原理解析.html-453c0561.js" as="script"><link rel="prefetch" href="/notebook/assets/小知识点.html-576e16e5.js" as="script"><link rel="prefetch" href="/notebook/assets/注解开发.html-6060f006.js" as="script"><link rel="prefetch" href="/notebook/assets/AOP.html-6fa5fadb.js" as="script"><link rel="prefetch" href="/notebook/assets/一个spring程序.html-c21d7044.js" as="script"><link rel="prefetch" href="/notebook/assets/声明式事务.html-b2c0f311.js" as="script"><link rel="prefetch" href="/notebook/assets/整合Mybatis.html-a347acec.js" as="script"><link rel="prefetch" href="/notebook/assets/Eureka.html-244a3c0f.js" as="script"><link rel="prefetch" href="/notebook/assets/Feign.html-62490d03.js" as="script"><link rel="prefetch" href="/notebook/assets/Hystrix.html-902868c2.js" as="script"><link rel="prefetch" href="/notebook/assets/Ribbon.html-220ad043.js" as="script"><link rel="prefetch" href="/notebook/assets/Zuul.html-19734fdf.js" as="script"><link rel="prefetch" href="/notebook/assets/初识SpringCloud.html-ca90e03a.js" as="script"><link rel="prefetch" href="/notebook/assets/Jdbc.html-73f4bf71.js" as="script"><link rel="prefetch" href="/notebook/assets/Shiro.html-b5e42919.js" as="script"><link rel="prefetch" href="/notebook/assets/Swagger.html-163a1cd4.js" as="script"><link rel="prefetch" href="/notebook/assets/Web静态资源处理.html-4eacdfc4.js" as="script"><link rel="prefetch" href="/notebook/assets/thymeleaf.html-6fe41ccd.js" as="script"><link rel="prefetch" href="/notebook/assets/分布式.html-e4e536cf.js" as="script"><link rel="prefetch" href="/notebook/assets/异步、定时、邮件任务.html-e7fe2c2a.js" as="script"><link rel="prefetch" href="/notebook/assets/整合mybatis.html-dc407a1d.js" as="script"><link rel="prefetch" href="/notebook/assets/第一天.html-5b45ced2.js" as="script"><link rel="prefetch" href="/notebook/assets/第二天.html-5dda30f7.js" as="script"><link rel="prefetch" href="/notebook/assets/ES6补充.html-668234e1.js" as="script"><link rel="prefetch" href="/notebook/assets/Vue基础.html-91a7a31f.js" as="script"><link rel="prefetch" href="/notebook/assets/Vue项目部署.html-1c3eb1d8.js" as="script"><link rel="prefetch" href="/notebook/assets/threejs的使用.html-350e2816.js" as="script"><link rel="prefetch" href="/notebook/assets/单文件组件.html-5bc8b3be.js" as="script"><link rel="prefetch" href="/notebook/assets/脚手架.html-ca084d7d.js" as="script"><link rel="prefetch" href="/notebook/assets/页面title.html-979513ef.js" as="script"><link rel="prefetch" href="/notebook/assets/Bitmaps.html-b806a27f.js" as="script"><link rel="prefetch" href="/notebook/assets/Hyperloglog.html-ccbee38e.js" as="script"><link rel="prefetch" href="/notebook/assets/Redis的基本事务操作.html-9277f0e7.js" as="script"><link rel="prefetch" href="/notebook/assets/redis-benchmark性能测试.html-0c4eea37.js" as="script"><link rel="prefetch" href="/notebook/assets/基本知识点.html-2442010c.js" as="script"><link rel="prefetch" href="/notebook/assets/安装.html-44dabf62.js" as="script"><link rel="prefetch" href="/notebook/assets/集成Redis.html-e0fe8e54.js" as="script"><link rel="prefetch" href="/notebook/assets/Center_pooling.html-7434a9ae.js" as="script"><link rel="prefetch" href="/notebook/assets/Focal_Loss.html-c736ff86.js" as="script"><link rel="prefetch" href="/notebook/assets/MAE.html-4785c79d.js" as="script"><link rel="prefetch" href="/notebook/assets/NMS非极大值抑制.html-8694503d.js" as="script"><link rel="prefetch" href="/notebook/assets/corner_pooling.html-1e3cd173.js" as="script"><link rel="prefetch" href="/notebook/assets/smooth_L1_loss.html-f9ed61b5.js" as="script"><link rel="prefetch" href="/notebook/assets/CMU motion capture.html-e2773175.js" as="script"><link rel="prefetch" href="/notebook/assets/Human3.6M.html-1f34af7d.js" as="script"><link rel="prefetch" href="/notebook/assets/Adapters.html-46c37106.js" as="script"><link rel="prefetch" href="/notebook/assets/CLIP.html-03a7b405.js" as="script"><link rel="prefetch" href="/notebook/assets/Faster_RCNN.html-4c33a2fb.js" as="script"><link rel="prefetch" href="/notebook/assets/MoCo.html-99e46914.js" as="script"><link rel="prefetch" href="/notebook/assets/RoI池化层.html-ab6c63f5.js" as="script"><link rel="prefetch" href="/notebook/assets/TCN.html-81df50ac.js" as="script"><link rel="prefetch" href="/notebook/assets/VAE.html-ff059abf.js" as="script"><link rel="prefetch" href="/notebook/assets/soft-argmax.html-238b0d93.js" as="script"><link rel="prefetch" href="/notebook/assets/元学习.html-8e751b92.js" as="script"><link rel="prefetch" href="/notebook/assets/反投影（back-projecting）.html-3e3d03e7.js" as="script"><link rel="prefetch" href="/notebook/assets/对比学习.html-834d7bdc.js" as="script"><link rel="prefetch" href="/notebook/assets/训练技巧.html-856fd83a.js" as="script"><link rel="prefetch" href="/notebook/assets/选择性搜索.html-30e2c070.js" as="script"><link rel="prefetch" href="/notebook/assets/A convnet for the 2020s.html-901e6ef5.js" as="script"><link rel="prefetch" href="/notebook/assets/Co-occurrence Feature Learning from Skeleton Data.html-0e29fe70.js" as="script"><link rel="prefetch" href="/notebook/assets/DETRs Beat YOLOs on Real-time Object Detection.html-2021478c.js" as="script"><link rel="prefetch" href="/notebook/assets/Disentangling Identity and Pose for Facial Expression Recognition.html-23fc93ca.js" as="script"><link rel="prefetch" href="/notebook/assets/EVOLVING REINFORCEMENT LEARNING ALGORITHMS.html-847e3006.js" as="script"><link rel="prefetch" href="/notebook/assets/Lite DETR An Interleaved Multi-Scale Encoder for Efficient DETR.html-ed1f2a21.js" as="script"><link rel="prefetch" href="/notebook/assets/Long-term Human Motion Prediction with Scene Context.html-a12c42cf.js" as="script"><link rel="prefetch" href="/notebook/assets/Real-time 2D Multi-Person Pose Estimation on CPU.html-00850641.js" as="script"><link rel="prefetch" href="/notebook/assets/SSHFD Single Shot Human Fall Detection with Occlud.html-fe4ba61a.js" as="script"><link rel="prefetch" href="/notebook/assets/Scaling Up Your Kernels to 31x31 Revisiting Large.html-9a8b9fcd.js" as="script"><link rel="prefetch" href="/notebook/assets/SkeleMotion A New Representation of Skeleton Joint.html-f48d52c4.js" as="script"><link rel="prefetch" href="/notebook/assets/Spatial Temporal Graph Convolutional Networks for.html-f7e0dab4.js" as="script"><link rel="prefetch" href="/notebook/assets/TSM Temporal Shift Module for Efficient Video Unde.html-e0f7bbc5.js" as="script"><link rel="prefetch" href="/notebook/assets/Towards Automated and Marker-less Parkinson Diseas.html-a172ea8a.js" as="script"><link rel="prefetch" href="/notebook/assets/Two-Stream Convolutional Networks for Action Recog.html-7320af12.js" as="script"><link rel="prefetch" href="/notebook/assets/🌟LoGoNet_ Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion.html-164878e0.js" as="script"><link rel="prefetch" href="/notebook/assets/概述.html-82ca03b1.js" as="script"><link rel="prefetch" href="/notebook/assets/时间序列模型.html-5eb2c87a.js" as="script"><link rel="prefetch" href="/notebook/assets/线性代数.html-9d56d107.js" as="script"><link rel="prefetch" href="/notebook/assets/存储器.html-f1724edc.js" as="script"><link rel="prefetch" href="/notebook/assets/系统总线.html-65a88c47.js" as="script"><link rel="prefetch" href="/notebook/assets/计算机基本组成.html-a6e6ab30.js" as="script"><link rel="prefetch" href="/notebook/assets/计算机的运算方法.html-06419318.js" as="script"><link rel="prefetch" href="/notebook/assets/输入输出系统.html-70cdf8b9.js" as="script"><link rel="prefetch" href="/notebook/assets/高速缓存存储器.html-c82d9391.js" as="script"><link rel="prefetch" href="/notebook/assets/JDBC.html-db742cd3.js" as="script"><link rel="prefetch" href="/notebook/assets/JSP.html-5694e9e1.js" as="script"><link rel="prefetch" href="/notebook/assets/Servlet.html-3f528292.js" as="script"><link rel="prefetch" href="/notebook/assets/Tomcat.html-8f5df9f1.js" as="script"><link rel="prefetch" href="/notebook/assets/监听器.html-6dce5d6f.js" as="script"><link rel="prefetch" href="/notebook/assets/缓存.html-bde43d43.js" as="script"><link rel="prefetch" href="/notebook/assets/过滤器.html-f022c23a.js" as="script"><link rel="prefetch" href="/notebook/assets/IO.html-8ff1d015.js" as="script"><link rel="prefetch" href="/notebook/assets/反射.html-74e5bb6a.js" as="script"><link rel="prefetch" href="/notebook/assets/容器.html-eeb7b705.js" as="script"><link rel="prefetch" href="/notebook/assets/泛型.html-909eb974.js" as="script"><link rel="prefetch" href="/notebook/assets/注解.html-5e39bee7.js" as="script"><link rel="prefetch" href="/notebook/assets/概述.html-61749c53.js" as="script"><link rel="prefetch" href="/notebook/assets/CRUD.html-f0ca6cf6.js" as="script"><link rel="prefetch" href="/notebook/assets/ResultMap结果集映射.html-d3230fa0.js" as="script"><link rel="prefetch" href="/notebook/assets/lombok.html-27a4c600.js" as="script"><link rel="prefetch" href="/notebook/assets/一对多.html-3397922b.js" as="script"><link rel="prefetch" href="/notebook/assets/分页.html-9eec0880.js" as="script"><link rel="prefetch" href="/notebook/assets/动态SQL.html-8d138e1b.js" as="script"><link rel="prefetch" href="/notebook/assets/日志.html-3d803ee9.js" as="script"><link rel="prefetch" href="/notebook/assets/概念.html-78ac39d6.js" as="script"><link rel="prefetch" href="/notebook/assets/注解开发.html-88569228.js" as="script"><link rel="prefetch" href="/notebook/assets/生命周期和作用域.html-c5d10be9.js" as="script"><link rel="prefetch" href="/notebook/assets/第一个Mybatis程序.html-e9c69dc2.js" as="script"><link rel="prefetch" href="/notebook/assets/缓存.html-e08eaa72.js" as="script"><link rel="prefetch" href="/notebook/assets/配置解析.html-4ecd170f.js" as="script"><link rel="prefetch" href="/notebook/assets/404.html-4e6aa668.js" as="script"><link rel="prefetch" href="/notebook/assets/style-e9220a04.js" as="script"><link rel="prefetch" href="/notebook/assets/docsearch-1d421ddb.js" as="script"><link rel="prefetch" href="/notebook/assets/index-ade63bb5.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/notebook/" class=""><!----><span class="site-name">记录</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/notebook/知识/数据结构.html" class="" aria-label="测试"><!--[--><!--]--> 测试 <!--[--><!--]--></a></div><div class="navbar-item"><a class="external-link" href="https://github.com/dtenghao?tab=repositories" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/notebook/知识/数据结构.html" class="" aria-label="测试"><!--[--><!--]--> 测试 <!--[--><!--]--></a></div><div class="navbar-item"><a class="external-link" href="https://github.com/dtenghao?tab=repositories" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">目录 <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#出发点" class="router-link-active router-link-exact-active sidebar-item" aria-label="出发点"><!--[--><!--]--> 出发点 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#模型" class="router-link-active router-link-exact-active sidebar-item" aria-label="模型"><!--[--><!--]--> 模型 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#多尺度图计算单元-mgcu" class="router-link-active router-link-exact-active sidebar-item" aria-label="多尺度图计算单元（MGCU）"><!--[--><!--]--> 多尺度图计算单元（MGCU） <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#graph-based-gru" class="router-link-active router-link-exact-active sidebar-item" aria-label="Graph-based GRU"><!--[--><!--]--> Graph-based GRU <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#差分操作" class="router-link-active router-link-exact-active sidebar-item" aria-label="差分操作"><!--[--><!--]--> 差分操作 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#模型总览" class="router-link-active router-link-exact-active sidebar-item" aria-label="模型总览"><!--[--><!--]--> 模型总览 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#实验" class="router-link-active router-link-exact-active sidebar-item" aria-label="实验"><!--[--><!--]--> 实验 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#数据集" class="router-link-active router-link-exact-active sidebar-item" aria-label="数据集"><!--[--><!--]--> 数据集 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#设置" class="router-link-active router-link-exact-active sidebar-item" aria-label="设置"><!--[--><!--]--> 设置 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#方法比较" class="router-link-active router-link-exact-active sidebar-item" aria-label="方法比较"><!--[--><!--]--> 方法比较 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Dynamic%20Multiscale%20Graph%20Neural%20Networks%20for%203D%20Skeleton-Based%20Human%20Motion%20Prediction.html#消融实验" class="router-link-active router-link-exact-active sidebar-item" aria-label="消融实验"><!--[--><!--]--> 消融实验 <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><blockquote><p>Li, Maosen, et al. &quot;Dynamic multiscale graph neural networks for 3 d skeleton based human motion prediction.&quot; <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 2020.</p></blockquote><h1 id="出发点" tabindex="-1"><a class="header-anchor" href="#出发点" aria-hidden="true">#</a> 出发点</h1><p>现有的人体运动预测算法通常只针对单一尺度上的人体结构、姿态和运动过程，即人体的基本单位是每个关节点。</p><p>然而，仅通过细粒度的“关节点级别”建模会放大一些不必要的信息，如采集和传输过程中的扰动和误差。</p><p>而且纯粹基于节点所建立的 graph 只能描述节点之间的二元关系，无法描述多个节点协同运动和群组交互关系。</p><hr><p>因此作者提出使用多尺度的 graph 来更好的学习运动特征。先学习单一尺度的特征，再将多尺度特征进行融合，将多尺度特征进行加权求和，</p><h1 id="模型" tabindex="-1"><a class="header-anchor" href="#模型" aria-hidden="true">#</a> 模型</h1><p>模型的主要流程：</p><ol><li>学习单一尺度的特征</li><li>多尺度特征进行融合</li><li>重复 1，2 两个步骤</li><li>将多尺度特征进行加权求和</li><li>将生成特征用于 GRU 单元，来不断生成未来的关节坐标</li></ol><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/09/image-20230509154031406.png" alt="image-20230509154031406"></p><h2 id="多尺度图计算单元-mgcu" tabindex="-1"><a class="header-anchor" href="#多尺度图计算单元-mgcu" aria-hidden="true">#</a> 多尺度图计算单元（MGCU）</h2><p>MGCU 有两个组件组成：</p><ol><li>单尺度图卷积块，利用单尺度图来提取特征</li><li>跨尺度融合块，利用跨尺度图来将一个尺度的特征转移到另一尺度，以实现不同尺度间的信息融合</li></ol><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/09/image-20230509211524218.png" alt="image-20230509211524218|650"></p><p><strong>==SS-GCB==</strong></p><p>该模块使用一个图卷积来提取空间特征 $$ \mathbf{X}_{s,\text{sp}}=\text{Re}\mathrm{LU}(\mathbf{A}_s\mathbf{X}_s\mathbf{W}_s+\mathbf{X}_s\mathbf{U}<em>s)\in\mathbb{R}^{M_s\times D&#39;</em>\mathbf{x}} $$ $\textbf{X}_s\in\mathbb{R}^{M_s\times D_x}$，是尺度 s 上的关节特征，$\textbf{A}_s\in\mathbb{R}^{M_s\times M_s}$ 是反应关节连接情况的邻接矩阵，由身体的物理连接初始化，矩阵可训练，在训练中不断调整。$\textbf{W}<em>s,\textbf{U}<em>s\in\mathbb{R}^{D</em>\textbf{x}\times D</em>\textbf{x}&#39;}$ 是 MLPs</p><p>使用时间卷积提取时间特征</p><p>==<strong>CS-FB</strong>==</p><p>跨尺度融合模块使用一个跨尺度图来将一个尺度上的特征转换到另一个尺度上</p><p>设邻接矩阵 $\textbf{A}<em>{s_1s_2}\in[0,1]^{M</em>{s_2}\times M_{s_1}}$，反应了尺度 $s_1$ 的关节点和尺度 $s_2$ 的关节点之间的关系</p><p>$\textbf{P}<em>{s_1,i}$ 表示 $s_1$ 第 i 个关节点的特征，同理 $\textbf{P}</em>{s_2,j}$</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/09/image-20230509213653686.png" alt="image-20230509213653686"></p><p>$[\cdot,\cdot]$ 表示拼接，先通过 2 a、2 b，2 c、2 d 学习到具有全局相对信息的特征，在对两个尺度的特征矩阵相乘，得到 $\textbf{A}_{s_1s_2}$ 邻接矩阵，下图展示了完整的流程</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/09/image-20230509214553582.png" alt="image-20230509214553582"></p><p>有了 $\textbf{A}<em>{s_1s_2}$ 邻接矩阵后，就可以使用图卷积来将 $s_1$ 尺度下的特征转化到 $s_2$ 尺度上来，再与原来的 $s_2$ 尺度特征相加，就得到了融合了 $s_1$ 尺度的 $s_2$ 尺度特征 $$ \textbf{X}</em>{s_2}\leftarrow\textbf{A}<em>{s_1s_2}\textbf{X}</em>{s_1}\textbf{W}<em>{\text{F},s_1}+\textbf{X}</em>{s_2}\in\mathbb{R}^{M_{s_2}\times D&#39;<em>\textbf{x}} $$ $\mathbf{W}</em>{\mathrm{F},s_1} \in \mathbb{R}^{D_x&#39;\times D_x}$ 是 MLPs</p><h2 id="graph-based-gru" tabindex="-1"><a class="header-anchor" href="#graph-based-gru" aria-hidden="true">#</a> Graph-based GRU</h2><p>模型使用基于图的 GRU 循环单元来学习和更新隐藏状态 $\textbf{H}^{(t)}\in\mathbb{R}^{M\times D_{\text{h}}}$，从而进一步计算关节信息 $\textbf{I}^{(t)}\in\mathbb{R}^{M\times d}$，这里的 d 不是关节坐标 xyz，而是坐标+速度+加速度等信息 $$ \begin{aligned} \textbf{r}^{(t)}&amp; =\sigma(r_\mathrm{in}(\mathbf{I}^{(t)})+r_\mathrm{hid}(\mathbf{A}<em>\mathrm{H}\mathbf{H}^{(t)}\mathbf{W}</em>\mathrm{H})), \ \textbf{u}^{(t)}&amp; =\sigma(u_{\mathrm{in}}(\mathbf{I}^{(t)})+u_{\mathrm{hid}}(\mathbf{A}<em>{\mathrm{H}}\mathbf{H}^{(t)}\mathbf{W}</em>{\mathrm{H}})), \ \textbf{c}^{(t)}&amp; =\tanh(c_{\text{in}}(\mathbf{I}^{(t)})+\mathbf{r}^{(t)}\odot c_{\text{hid}}(\mathbf{A}<em>{\text{H}}\mathbf{H}^{(t)}\mathbf{W}</em>{\text{H}})), \ \textbf{H}^{(t+1)}&amp; =\mathbf{u}^{(t)}\odot\mathbf{H}^{(t)}+(1-\mathbf{u}^{(t)})\odot\mathbf{c}^{(t)}, \end{aligned} $$ $r_{\text{in}}(\cdot),r_{\text{hid}}(\cdot),u_{\text{in}}(\cdot),u_{\text{hid}}(\cdot),c_{\text{in}}(\cdot)c_{\text{hid}}(\cdot)$ 和 $W_H$ 都是 MLPs</p><h2 id="差分操作" tabindex="-1"><a class="header-anchor" href="#差分操作" aria-hidden="true">#</a> 差分操作</h2><p>令 $\Delta^0\textbf{X}^{(t)}=\textbf{X}^{(t)}\in\mathbb{R}^{M\times D_\textbf{x}}$，$\begin{aligned} \Delta^{\beta}\textbf{X}^{(t)}&amp; =\Delta^{\beta-1}\textbf{X}^{(t)}-\Delta^{\beta-1}\textbf{X}^{(t-1)} \end{aligned}$</p><p>差分是边界情况使用 0 填充，因此差分操作为： $$ \text{diff}_{\beta}(\mathbf{X}^{(t)})=\begin{bmatrix}\Delta^0\textbf{X}^{(t)}&amp;\cdots&amp;\Delta^{\beta}\textbf{X}^{(t)}\ \end{bmatrix} $$ 论文使用 $\beta=2$，因此会得到三个元素，分别是位置，速度，加速度</p><h2 id="模型总览" tabindex="-1"><a class="header-anchor" href="#模型总览" aria-hidden="true">#</a> 模型总览</h2><p><strong>==Encoder==</strong></p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/09/image-20230509220912558.png" alt="image-20230509220912558"></p><ol><li><p>将骨架坐标转化为三阶差分</p></li><li><p>粗尺度的特征为相应细尺度关节特征的平均</p></li><li><p>将三个尺度输入到 MGCU</p></li><li><p>最后将三个尺度的特征加权求和（由于粗粒度关节点少，因此将粗粒度关节特征广播到细粒度） $$ \mathbb{H}=\mathbb{H}<em>{s_1}+\lambda(\mathbb{H}</em>{s_2}+\mathbb{H}<em>{s_3}) $$ $\lambda$ 是超参数，$\mathbb{H}</em>{s_1},\mathbb{H}<em>{s_2},\mathbb{H}</em>{s_3}\in\mathbb{R}^{T&#39;\times M\times D_{\text{h}}}$</p></li><li><p>最后使用一个时间平均池化来移除时间维度，得到 $\begin{aligned}\textbf{H}&amp; \in\mathbb{R}^{M\times D_{\mathbf{h}}} \end{aligned}$</p></li></ol><p>==<strong>Decoder</strong>==</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/09/image-20230509221732546.png" alt="image-20230509221732546|550"></p><ol><li><p>先根据坐标获得三阶差分</p></li><li><p>利用三阶差分和上一时间的隐藏状态输入 GRU 得到当前时间隐藏状态</p></li><li><p>再将隐藏状态通过 MLP 求的坐标 offsets，与当前时刻的坐标相加，就得到了下一时刻的坐标 $$ \widehat{\mathbf{X}}^{(t+1)}=\widehat{\mathbf{X}}^{(t)}+f_{\text{pred}}\left(\text{G-GRU}\left(\text{diff}<em>2(\widehat{\mathbf{X}}^{(t)}),\mathbf{H}^{(t)}\right)\right) $$ $f</em>{\text{pred}}$ 是 MLPs</p></li></ol><p><strong>==Loss function==</strong></p><p>损失函数使用 $l_1$ 损失，对于拥有小 loss 的关节来说，可以提供足够的梯度，对于拥有大 loss 的关节来说，也可以提供稳定的梯度 $$ \mathcal{L}<em>{\text{pred}}=\frac{1}{N}\sum</em>{n=1}^N\left|(\mathbb{X}<em>{1:T</em>\mathfrak{f}})<em>n-(\widehat{\mathbb{X}}</em>{1:T_\mathfrak{f}})_n\right|_1 $$ $N$ 是样本数，公式表示对所有样本的预测坐标与真实坐标求 $l_1$ loss，再取平均</p><h1 id="实验" tabindex="-1"><a class="header-anchor" href="#实验" aria-hidden="true">#</a> 实验</h1><h2 id="数据集" tabindex="-1"><a class="header-anchor" href="#数据集" aria-hidden="true">#</a> 数据集</h2><p>本文使用数据集包含了：</p><ol><li><p><a href="/notebook/%E7%A7%91%E7%A0%94/%E6%95%B0%E6%8D%AE%E9%9B%86/Human3.6M.html" class="">Human3.6M</a></p><p>将关节坐标转换为指数映射 (exponential maps，是一种描述 3 D 旋转的方式，非零指数映射的关节表示这些关节在运动中确实发生了旋转)，并且只使用非零值的关节 (剩下 20 个关节)，同时在时间维度上，下采样了两倍</p></li><li><p><a href="/notebook/%E7%A7%91%E7%A0%94/%E6%95%B0%E6%8D%AE%E9%9B%86/CMU%20motion%20capture.html" class="">CMU motion capture</a></p><p>只保留了有非零指数映射的 26 个关节，选择了8种详细的动作进行分析：&#39;篮球&#39;，&#39;篮球手势&#39;，&#39;指挥交通&#39;，&#39;跳跃&#39;，&#39;跑步&#39;，&#39;足球&#39;，&#39;走路&#39;和&#39;擦窗户&#39;</p></li></ol><h2 id="设置" tabindex="-1"><a class="header-anchor" href="#设置" aria-hidden="true">#</a> 设置</h2><ol><li><strong>尺度设置</strong>：设置了3个尺度，包括身体关节，10个和5个身体组件，这适用于两个数据集。</li><li><strong>MGCUs</strong>：使用了4个级联的MGCUs（Multi-Scale Graph Convolution Units），特征维度分别为32，64，128和256。在前两个MGCUs中，他们使用SS-GCBs（Self-Similarity Graph Convolution Blocks）和CS-FBs（Cross-Scale Fusion Blocks）来提取时空特征和融合跨尺度特征；在最后两个MGCUs中，他们只使用SS-GCBs。</li><li><strong>解码器</strong>：在解码器中，G-GRU（Gated Graph Recurrent Unit）的维度是256，使用了一个两层的多层感知器（MLP）来输出姿态。</li><li><strong>训练设置</strong>：在训练过程中，他们设置了批大小为32，并将梯度剪切到最大的l2范数为0.5；使用了Adam优化器，学习率为0.0001。</li><li><strong>超参数选择</strong>：所有的超参数都是通过验证集来选择的</li><li><strong>实现平台</strong>：他们使用PyTorch 1.0实现了DMGNN模型，并在一块RTX-2080Ti GPU上进行训练。</li></ol><h2 id="方法比较" tabindex="-1"><a class="header-anchor" href="#方法比较" aria-hidden="true">#</a> 方法比较</h2><p>评价指标上选用 mean angle error (<a href="/notebook/%E7%A7%91%E7%A0%94/tricks/MAE.html" class="">MAE</a>)</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510163006082.png" alt="image-20230510163006082"></p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510163259601.png" alt="image-20230510163259601"></p><p>比较了论文模型与其他先进的模型在**==短期运动预测==**（预测未来500毫秒内的姿态）上的表现，基本上达到了SOTA的性能，但在Discussion和Directions上表现还不足</p><p>在**==长期运动预测==**上，DMGNN也提供了不错的表现</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510163657814.png" alt="image-20230510163657814"></p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510163711528.png" alt="image-20230510163711528"></p><p>同时在==<strong>耗时</strong>==方面，DMGNN也取得了最好的效果</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510163856410.png" alt="image-20230510163856410"></p><p>结果表明，所提出的模型在短期和长期预测方面的有效性和效率都优于大多数最先进的方法。</p><h2 id="消融实验" tabindex="-1"><a class="header-anchor" href="#消融实验" aria-hidden="true">#</a> 消融实验</h2><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510164040964.png" alt="image-20230510164040964"></p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510164102326.png" alt="image-20230510164102326"></p><hr><p>模型对三个尺度特征加权求和的超参数$\lambda$具有鲁棒性</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510164507453.png" alt="image-20230510164507453"></p><hr><p>最后作者还做出了一下分析</p><ol><li><p><strong>验证DMGNN的特征学习能力</strong>：作者首先测试了DMGNN模型学习到的跨尺度图表（cross-scale graphs）对不同动作的区分能力。他们展示了H3.6M数据集中&#39;Walking&#39;和&#39;Directions&#39;两种动作在两个CS-FBs（Cross-Scale Fusion Blocks）中的图表。对于每种动作，他们展示了从详细尺度到粗尺度右臂的一些强关联。从结果中，他们发现i) 对于每种动作，CS-FBs都能捕捉到人体的各种范围：第一个CS-FB主要关注附近的身体组件，第二个CS-FB捕捉到更全局和与动作相关的影响，例如在走路时，手和脚影响到手臂；ii) 对于不同的动作，跨尺度图是不同的，特别是在第二个CS-FB中，捕捉到了不同的模式。</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510165008873.png" alt="image-20230510165008873"></p></li><li><p><strong>动作分类测试</strong>：然后，他们在中间表示上进行动作分类，以测试模型的区分能力。他们单独训练了一个两层的多层感知器（MLP）来对每个动态的跨尺度图进行分类。他们还分类了来自DMGNN、Res-sup（有类别的）和TP-RNN（无类别的）的编码器的输出。表10展示了对15种动作类别的平均分类准确率。他们发现，第二个CS-FB中的跨尺度图比第一个CS-FB中的对动作识别更有信息量。与基线方法相比，DMGNN在编码器表示上获得了最高的分类准确率，这表明DMGNN捕捉到了对无类别预测有区分性的信息。</p><p><img src="https://raw.githubusercontent.com/0Eumenides/upic/main/2023/05/10/image-20230510165110939.png" alt="image-20230510165110939"></p></li></ol></div><!--[--><!--]--></div><footer class="page-meta"><div class="meta-item edit-link"><a class="external-link meta-item-label" href="https://github.com/dtenghao?tab=repositories/edit/main/科研/论文笔记/Dynamic Multiscale Graph Neural Networks for 3D Skeleton-Based Human Motion Prediction.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page"><!--[--><!--]--> Edit this page <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!----><!----></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/notebook/assets/app-29aba0ee.js" defer></script>
  </body>
</html>
